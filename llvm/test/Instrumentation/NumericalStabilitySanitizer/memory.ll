; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -mtriple=x86_64-linux-gnu < %s -nsan -nsan-shadow-type-mapping=dqq -S | FileCheck %s
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"

; Tests with memory manipulation (memcpy, llvm.memcpy, ...).


declare void @llvm.memcpy.p0i8.p0i8.i64(i8*, i8*, i64, i1)

define void @call_memcpy_intrinsic(i8* nonnull align 8 dereferenceable(16) %a, i8* nonnull align 8 dereferenceable(16) %b) sanitize_numericalstability {
; CHECK-LABEL: @call_memcpy_intrinsic(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    call void @__nsan_copy_values(i8* [[A:%.*]], i8* [[B:%.*]], i64 16)
; CHECK-NEXT:    tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) [[A]], i8* nonnull align 8 dereferenceable(16) [[B]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
entry:
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %a, i8* nonnull align 8 dereferenceable(16) %b, i64 16, i1 false)
  ret void
}

declare dso_local i8* @memcpy(i8*, i8*, i64) local_unnamed_addr

define void @call_memcpy(i8* nonnull align 8 dereferenceable(16) %a, i8* nonnull align 8 dereferenceable(16) %b) sanitize_numericalstability {
; CHECK-LABEL: @call_memcpy(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = tail call i8* @memcpy(i8* nonnull align 8 dereferenceable(16) [[A:%.*]], i8* nonnull align 8 dereferenceable(16) [[B:%.*]], i64 16) #3
; CHECK-NEXT:    ret void
;
entry:
  tail call i8* @memcpy(i8* nonnull align 8 dereferenceable(16) %a, i8* nonnull align 8 dereferenceable(16) %b, i64 16)
  ret void
}


define void @transfer_float(float* %dst, float* %src) sanitize_numericalstability {
; CHECK-LABEL: @transfer_float(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[T:%.*]] = load float, float* [[SRC:%.*]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast float* [[SRC]] to i8*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP0]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq i8* [[TMP1]], null
; CHECK-NEXT:    br i1 [[TMP2]], label [[TMP6:%.*]], label [[TMP3:%.*]]
; CHECK:       3:
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i8* [[TMP1]] to double*
; CHECK-NEXT:    [[TMP5:%.*]] = load double, double* [[TMP4]], align 1
; CHECK-NEXT:    br label [[TMP8:%.*]]
; CHECK:       6:
; CHECK-NEXT:    [[TMP7:%.*]] = fpext float [[T]] to double
; CHECK-NEXT:    br label [[TMP8]]
; CHECK:       8:
; CHECK-NEXT:    [[TMP9:%.*]] = phi double [ [[TMP5]], [[TMP3]] ], [ [[TMP7]], [[TMP6]] ]
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast float* [[DST:%.*]] to i8*
; CHECK-NEXT:    [[TMP11:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP10]], i64 1)
; CHECK-NEXT:    [[TMP12:%.*]] = ptrtoint float* [[DST]] to i64
; CHECK-NEXT:    [[TMP13:%.*]] = call i32 @__nsan_internal_check_float_d(float [[T]], double [[TMP9]], i32 4, i64 [[TMP12]])
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP13]], 1
; CHECK-NEXT:    [[TMP15:%.*]] = fpext float [[T]] to double
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP14]], double [[TMP15]], double [[TMP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP11]] to double*
; CHECK-NEXT:    store double [[TMP16]], double* [[TMP17]], align 1
; CHECK-NEXT:    store float [[T]], float* [[DST]], align 1
; CHECK-NEXT:    ret void
;
entry:
  %t = load float, float* %src
  store float %t, float* %dst, align 1
  ret void
}

define void @transfer_non_float(i32* %dst, i32* %src) sanitize_numericalstability {
; CHECK-LABEL: @transfer_non_float(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[T:%.*]] = load i32, i32* [[SRC:%.*]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32* [[SRC]] to i8*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i32*
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[TMP2]], align 1
; CHECK-NEXT:    [[TMP4:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP0]])
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP4]] to i64*
; CHECK-NEXT:    [[TMP6:%.*]] = load i64, i64* [[TMP5]], align 1
; CHECK-NEXT:    store i32 [[T]], i32* [[DST:%.*]], align 1
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i32* [[DST]] to i8*
; CHECK-NEXT:    [[TMP8:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i8* [[TMP8]] to i32*
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[TMP9]], align 1
; CHECK-NEXT:    [[TMP10:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP7]])
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i8* [[TMP10]] to i64*
; CHECK-NEXT:    store i64 [[TMP6]], i64* [[TMP11]], align 1
; CHECK-NEXT:    ret void
;
entry:
  %t = load i32, i32* %src
  store i32 %t, i32* %dst, align 1
  ret void
}

define void @transfer_array([2 x float]* %a) sanitize_numericalstability {
; CHECK-LABEL: @transfer_array(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[B:%.*]] = load [2 x float], [2 x float]* [[A:%.*]], align 1
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [2 x float]* [[A]] to i8*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP0]])
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i64*
; CHECK-NEXT:    [[TMP3:%.*]] = load i64, i64* [[TMP2]], align 1
; CHECK-NEXT:    [[TMP4:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP0]])
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP4]] to i128*
; CHECK-NEXT:    [[TMP6:%.*]] = load i128, i128* [[TMP5]], align 1
; CHECK-NEXT:    store [2 x float] [[B]], [2 x float]* [[A]], align 1
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast [2 x float]* [[A]] to i8*
; CHECK-NEXT:    [[TMP8:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i8* [[TMP8]] to i64*
; CHECK-NEXT:    store i64 [[TMP3]], i64* [[TMP9]], align 1
; CHECK-NEXT:    [[TMP10:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP7]])
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i8* [[TMP10]] to i128*
; CHECK-NEXT:    store i128 [[TMP6]], i128* [[TMP11]], align 1
; CHECK-NEXT:    ret void
;
entry:
  %b = load [2 x float], [2 x float]* %a, align 1
  store [2 x float] %b, [2 x float]* %a, align 1
  ret void
}

define void @swap_untyped1(i64* nonnull align 8 %p, i64* nonnull align 8 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_untyped1(
; CHECK-NEXT:    [[QV:%.*]] = load i64, i64* [[Q:%.*]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64* [[Q]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i8* [[TMP2]] to i64*
; CHECK-NEXT:    [[TMP4:%.*]] = load i64, i64* [[TMP3]], align 1
; CHECK-NEXT:    [[TMP5:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP1]])
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i8* [[TMP5]] to i128*
; CHECK-NEXT:    [[TMP7:%.*]] = load i128, i128* [[TMP6]], align 1
; CHECK-NEXT:    [[PV:%.*]] = load i64, i64* [[P:%.*]], align 8
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i64* [[P]] to i8*
; CHECK-NEXT:    [[TMP9:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8* [[TMP9]] to i64*
; CHECK-NEXT:    [[TMP11:%.*]] = load i64, i64* [[TMP10]], align 1
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP8]])
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast i8* [[TMP12]] to i128*
; CHECK-NEXT:    [[TMP14:%.*]] = load i128, i128* [[TMP13]], align 1
; CHECK-NEXT:    store i64 [[PV]], i64* [[Q]], align 8
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i64* [[Q]] to i8*
; CHECK-NEXT:    [[TMP16:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP15]])
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP16]] to i64*
; CHECK-NEXT:    store i64 [[TMP11]], i64* [[TMP17]], align 1
; CHECK-NEXT:    [[TMP18:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP15]])
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i8* [[TMP18]] to i128*
; CHECK-NEXT:    store i128 [[TMP14]], i128* [[TMP19]], align 1
; CHECK-NEXT:    store i64 [[QV]], i64* [[P]], align 8
; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i64* [[P]] to i8*
; CHECK-NEXT:    [[TMP21:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP20]])
; CHECK-NEXT:    [[TMP22:%.*]] = bitcast i8* [[TMP21]] to i64*
; CHECK-NEXT:    store i64 [[TMP4]], i64* [[TMP22]], align 1
; CHECK-NEXT:    [[TMP23:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP20]])
; CHECK-NEXT:    [[TMP24:%.*]] = bitcast i8* [[TMP23]] to i128*
; CHECK-NEXT:    store i128 [[TMP7]], i128* [[TMP24]], align 1
; CHECK-NEXT:    ret void
;
  %qv = load i64, i64* %q
  %pv = load i64, i64* %p
  store i64 %pv, i64* %q, align 8
  store i64 %qv, i64* %p, align 8
  ret void
}

; Same as swap_untyped1, but the load/stores are in the opposite order.
define void @swap_untyped2(i64* nonnull align 8 %p, i64* nonnull align 8 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_untyped2(
; CHECK-NEXT:    [[PV:%.*]] = load i64, i64* [[P:%.*]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i8* [[TMP2]] to i64*
; CHECK-NEXT:    [[TMP4:%.*]] = load i64, i64* [[TMP3]], align 1
; CHECK-NEXT:    [[TMP5:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP1]])
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i8* [[TMP5]] to i128*
; CHECK-NEXT:    [[TMP7:%.*]] = load i128, i128* [[TMP6]], align 1
; CHECK-NEXT:    [[QV:%.*]] = load i64, i64* [[Q:%.*]], align 8
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i64* [[Q]] to i8*
; CHECK-NEXT:    [[TMP9:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8* [[TMP9]] to i64*
; CHECK-NEXT:    [[TMP11:%.*]] = load i64, i64* [[TMP10]], align 1
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP8]])
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast i8* [[TMP12]] to i128*
; CHECK-NEXT:    [[TMP14:%.*]] = load i128, i128* [[TMP13]], align 1
; CHECK-NEXT:    store i64 [[PV]], i64* [[Q]], align 8
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i64* [[Q]] to i8*
; CHECK-NEXT:    [[TMP16:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP15]])
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP16]] to i64*
; CHECK-NEXT:    store i64 [[TMP4]], i64* [[TMP17]], align 1
; CHECK-NEXT:    [[TMP18:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP15]])
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i8* [[TMP18]] to i128*
; CHECK-NEXT:    store i128 [[TMP7]], i128* [[TMP19]], align 1
; CHECK-NEXT:    store i64 [[QV]], i64* [[P]], align 8
; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i64* [[P]] to i8*
; CHECK-NEXT:    [[TMP21:%.*]] = call i8* @__nsan_internal_get_raw_shadow_type_ptr(i8* [[TMP20]])
; CHECK-NEXT:    [[TMP22:%.*]] = bitcast i8* [[TMP21]] to i64*
; CHECK-NEXT:    store i64 [[TMP11]], i64* [[TMP22]], align 1
; CHECK-NEXT:    [[TMP23:%.*]] = call i8* @__nsan_internal_get_raw_shadow_ptr(i8* [[TMP20]])
; CHECK-NEXT:    [[TMP24:%.*]] = bitcast i8* [[TMP23]] to i128*
; CHECK-NEXT:    store i128 [[TMP14]], i128* [[TMP24]], align 1
; CHECK-NEXT:    ret void
;
  %pv = load i64, i64* %p
  %qv = load i64, i64* %q
  store i64 %pv, i64* %q, align 8
  store i64 %qv, i64* %p, align 8
  ret void
}

define void @swap_ft1(float* nonnull align 8 %p, float* nonnull align 8 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_ft1(
; CHECK-NEXT:    [[QV:%.*]] = load float, float* [[Q:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast float* [[Q]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP1]], i64 1)
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[TMP3]], label [[TMP7:%.*]], label [[TMP4:%.*]]
; CHECK:       4:
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP2]] to double*
; CHECK-NEXT:    [[TMP6:%.*]] = load double, double* [[TMP5]], align 1
; CHECK-NEXT:    br label [[TMP9:%.*]]
; CHECK:       7:
; CHECK-NEXT:    [[TMP8:%.*]] = fpext float [[QV]] to double
; CHECK-NEXT:    br label [[TMP9]]
; CHECK:       9:
; CHECK-NEXT:    [[TMP10:%.*]] = phi double [ [[TMP6]], [[TMP4]] ], [ [[TMP8]], [[TMP7]] ]
; CHECK-NEXT:    [[PV:%.*]] = load float, float* [[P:%.*]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast float* [[P]] to i8*
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP11]], i64 1)
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i8* [[TMP12]], null
; CHECK-NEXT:    br i1 [[TMP13]], label [[TMP17:%.*]], label [[TMP14:%.*]]
; CHECK:       14:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP12]] to double*
; CHECK-NEXT:    [[TMP16:%.*]] = load double, double* [[TMP15]], align 1
; CHECK-NEXT:    br label [[TMP19:%.*]]
; CHECK:       17:
; CHECK-NEXT:    [[TMP18:%.*]] = fpext float [[PV]] to double
; CHECK-NEXT:    br label [[TMP19]]
; CHECK:       19:
; CHECK-NEXT:    [[TMP20:%.*]] = phi double [ [[TMP16]], [[TMP14]] ], [ [[TMP18]], [[TMP17]] ]
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast float* [[Q]] to i8*
; CHECK-NEXT:    [[TMP22:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP21]], i64 1)
; CHECK-NEXT:    [[TMP23:%.*]] = ptrtoint float* [[Q]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = call i32 @__nsan_internal_check_float_d(float [[PV]], double [[TMP20]], i32 4, i64 [[TMP23]])
; CHECK-NEXT:    [[TMP25:%.*]] = icmp eq i32 [[TMP24]], 1
; CHECK-NEXT:    [[TMP26:%.*]] = fpext float [[PV]] to double
; CHECK-NEXT:    [[TMP27:%.*]] = select i1 [[TMP25]], double [[TMP26]], double [[TMP20]]
; CHECK-NEXT:    [[TMP28:%.*]] = bitcast i8* [[TMP22]] to double*
; CHECK-NEXT:    store double [[TMP27]], double* [[TMP28]], align 1
; CHECK-NEXT:    store float [[PV]], float* [[Q]], align 8
; CHECK-NEXT:    [[TMP29:%.*]] = bitcast float* [[P]] to i8*
; CHECK-NEXT:    [[TMP30:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP29]], i64 1)
; CHECK-NEXT:    [[TMP31:%.*]] = ptrtoint float* [[P]] to i64
; CHECK-NEXT:    [[TMP32:%.*]] = call i32 @__nsan_internal_check_float_d(float [[QV]], double [[TMP10]], i32 4, i64 [[TMP31]])
; CHECK-NEXT:    [[TMP33:%.*]] = icmp eq i32 [[TMP32]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = fpext float [[QV]] to double
; CHECK-NEXT:    [[TMP35:%.*]] = select i1 [[TMP33]], double [[TMP34]], double [[TMP10]]
; CHECK-NEXT:    [[TMP36:%.*]] = bitcast i8* [[TMP30]] to double*
; CHECK-NEXT:    store double [[TMP35]], double* [[TMP36]], align 1
; CHECK-NEXT:    store float [[QV]], float* [[P]], align 8
; CHECK-NEXT:    ret void
;
  %qv = load float, float* %q
  %pv = load float, float* %p
  store float %pv, float* %q, align 8
  store float %qv, float* %p, align 8
  ret void
}

; Same as swap_ft1, but the load/stores are in the opposite order.
define void @swap_ft2(float* nonnull align 8 %p, float* nonnull align 8 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_ft2(
; CHECK-NEXT:    [[PV:%.*]] = load float, float* [[P:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast float* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP1]], i64 1)
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[TMP3]], label [[TMP7:%.*]], label [[TMP4:%.*]]
; CHECK:       4:
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP2]] to double*
; CHECK-NEXT:    [[TMP6:%.*]] = load double, double* [[TMP5]], align 1
; CHECK-NEXT:    br label [[TMP9:%.*]]
; CHECK:       7:
; CHECK-NEXT:    [[TMP8:%.*]] = fpext float [[PV]] to double
; CHECK-NEXT:    br label [[TMP9]]
; CHECK:       9:
; CHECK-NEXT:    [[TMP10:%.*]] = phi double [ [[TMP6]], [[TMP4]] ], [ [[TMP8]], [[TMP7]] ]
; CHECK-NEXT:    [[QV:%.*]] = load float, float* [[Q:%.*]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast float* [[Q]] to i8*
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP11]], i64 1)
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i8* [[TMP12]], null
; CHECK-NEXT:    br i1 [[TMP13]], label [[TMP17:%.*]], label [[TMP14:%.*]]
; CHECK:       14:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP12]] to double*
; CHECK-NEXT:    [[TMP16:%.*]] = load double, double* [[TMP15]], align 1
; CHECK-NEXT:    br label [[TMP19:%.*]]
; CHECK:       17:
; CHECK-NEXT:    [[TMP18:%.*]] = fpext float [[QV]] to double
; CHECK-NEXT:    br label [[TMP19]]
; CHECK:       19:
; CHECK-NEXT:    [[TMP20:%.*]] = phi double [ [[TMP16]], [[TMP14]] ], [ [[TMP18]], [[TMP17]] ]
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast float* [[Q]] to i8*
; CHECK-NEXT:    [[TMP22:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP21]], i64 1)
; CHECK-NEXT:    [[TMP23:%.*]] = ptrtoint float* [[Q]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = call i32 @__nsan_internal_check_float_d(float [[PV]], double [[TMP10]], i32 4, i64 [[TMP23]])
; CHECK-NEXT:    [[TMP25:%.*]] = icmp eq i32 [[TMP24]], 1
; CHECK-NEXT:    [[TMP26:%.*]] = fpext float [[PV]] to double
; CHECK-NEXT:    [[TMP27:%.*]] = select i1 [[TMP25]], double [[TMP26]], double [[TMP10]]
; CHECK-NEXT:    [[TMP28:%.*]] = bitcast i8* [[TMP22]] to double*
; CHECK-NEXT:    store double [[TMP27]], double* [[TMP28]], align 1
; CHECK-NEXT:    store float [[PV]], float* [[Q]], align 8
; CHECK-NEXT:    [[TMP29:%.*]] = bitcast float* [[P]] to i8*
; CHECK-NEXT:    [[TMP30:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP29]], i64 1)
; CHECK-NEXT:    [[TMP31:%.*]] = ptrtoint float* [[P]] to i64
; CHECK-NEXT:    [[TMP32:%.*]] = call i32 @__nsan_internal_check_float_d(float [[QV]], double [[TMP20]], i32 4, i64 [[TMP31]])
; CHECK-NEXT:    [[TMP33:%.*]] = icmp eq i32 [[TMP32]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = fpext float [[QV]] to double
; CHECK-NEXT:    [[TMP35:%.*]] = select i1 [[TMP33]], double [[TMP34]], double [[TMP20]]
; CHECK-NEXT:    [[TMP36:%.*]] = bitcast i8* [[TMP30]] to double*
; CHECK-NEXT:    store double [[TMP35]], double* [[TMP36]], align 1
; CHECK-NEXT:    store float [[QV]], float* [[P]], align 8
; CHECK-NEXT:    ret void
;
  %pv = load float, float* %p
  %qv = load float, float* %q
  store float %pv, float* %q, align 8
  store float %qv, float* %p, align 8
  ret void
}

define void @swap_vectorft1(<2 x float>* nonnull align 16 %p, <2 x float>* nonnull align 16 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_vectorft1(
; CHECK-NEXT:    [[QV:%.*]] = load <2 x float>, <2 x float>* [[Q:%.*]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x float>* [[Q]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP1]], i64 2)
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[TMP3]], label [[TMP7:%.*]], label [[TMP4:%.*]]
; CHECK:       4:
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP2]] to <2 x double>*
; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x double>, <2 x double>* [[TMP5]], align 1
; CHECK-NEXT:    br label [[TMP9:%.*]]
; CHECK:       7:
; CHECK-NEXT:    [[TMP8:%.*]] = fpext <2 x float> [[QV]] to <2 x double>
; CHECK-NEXT:    br label [[TMP9]]
; CHECK:       9:
; CHECK-NEXT:    [[TMP10:%.*]] = phi <2 x double> [ [[TMP6]], [[TMP4]] ], [ [[TMP8]], [[TMP7]] ]
; CHECK-NEXT:    [[PV:%.*]] = load <2 x float>, <2 x float>* [[P:%.*]], align 8
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <2 x float>* [[P]] to i8*
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP11]], i64 2)
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i8* [[TMP12]], null
; CHECK-NEXT:    br i1 [[TMP13]], label [[TMP17:%.*]], label [[TMP14:%.*]]
; CHECK:       14:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP12]] to <2 x double>*
; CHECK-NEXT:    [[TMP16:%.*]] = load <2 x double>, <2 x double>* [[TMP15]], align 1
; CHECK-NEXT:    br label [[TMP19:%.*]]
; CHECK:       17:
; CHECK-NEXT:    [[TMP18:%.*]] = fpext <2 x float> [[PV]] to <2 x double>
; CHECK-NEXT:    br label [[TMP19]]
; CHECK:       19:
; CHECK-NEXT:    [[TMP20:%.*]] = phi <2 x double> [ [[TMP16]], [[TMP14]] ], [ [[TMP18]], [[TMP17]] ]
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <2 x float>* [[Q]] to i8*
; CHECK-NEXT:    [[TMP22:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP21]], i64 2)
; CHECK-NEXT:    [[TMP23:%.*]] = extractelement <2 x float> [[PV]], i64 0
; CHECK-NEXT:    [[TMP24:%.*]] = extractelement <2 x double> [[TMP20]], i64 0
; CHECK-NEXT:    [[TMP25:%.*]] = ptrtoint <2 x float>* [[Q]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP23]], double [[TMP24]], i32 4, i64 [[TMP25]])
; CHECK-NEXT:    [[TMP27:%.*]] = extractelement <2 x float> [[PV]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = extractelement <2 x double> [[TMP20]], i64 1
; CHECK-NEXT:    [[TMP29:%.*]] = ptrtoint <2 x float>* [[Q]] to i64
; CHECK-NEXT:    [[TMP30:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP27]], double [[TMP28]], i32 4, i64 [[TMP29]])
; CHECK-NEXT:    [[TMP31:%.*]] = or i32 [[TMP26]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = icmp eq i32 [[TMP31]], 1
; CHECK-NEXT:    [[TMP33:%.*]] = fpext <2 x float> [[PV]] to <2 x double>
; CHECK-NEXT:    [[TMP34:%.*]] = select i1 [[TMP32]], <2 x double> [[TMP33]], <2 x double> [[TMP20]]
; CHECK-NEXT:    [[TMP35:%.*]] = bitcast i8* [[TMP22]] to <2 x double>*
; CHECK-NEXT:    store <2 x double> [[TMP34]], <2 x double>* [[TMP35]], align 1
; CHECK-NEXT:    store <2 x float> [[PV]], <2 x float>* [[Q]], align 16
; CHECK-NEXT:    [[TMP36:%.*]] = bitcast <2 x float>* [[P]] to i8*
; CHECK-NEXT:    [[TMP37:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP36]], i64 2)
; CHECK-NEXT:    [[TMP38:%.*]] = extractelement <2 x float> [[QV]], i64 0
; CHECK-NEXT:    [[TMP39:%.*]] = extractelement <2 x double> [[TMP10]], i64 0
; CHECK-NEXT:    [[TMP40:%.*]] = ptrtoint <2 x float>* [[P]] to i64
; CHECK-NEXT:    [[TMP41:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP38]], double [[TMP39]], i32 4, i64 [[TMP40]])
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <2 x float> [[QV]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = extractelement <2 x double> [[TMP10]], i64 1
; CHECK-NEXT:    [[TMP44:%.*]] = ptrtoint <2 x float>* [[P]] to i64
; CHECK-NEXT:    [[TMP45:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP42]], double [[TMP43]], i32 4, i64 [[TMP44]])
; CHECK-NEXT:    [[TMP46:%.*]] = or i32 [[TMP41]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = icmp eq i32 [[TMP46]], 1
; CHECK-NEXT:    [[TMP48:%.*]] = fpext <2 x float> [[QV]] to <2 x double>
; CHECK-NEXT:    [[TMP49:%.*]] = select i1 [[TMP47]], <2 x double> [[TMP48]], <2 x double> [[TMP10]]
; CHECK-NEXT:    [[TMP50:%.*]] = bitcast i8* [[TMP37]] to <2 x double>*
; CHECK-NEXT:    store <2 x double> [[TMP49]], <2 x double>* [[TMP50]], align 1
; CHECK-NEXT:    store <2 x float> [[QV]], <2 x float>* [[P]], align 16
; CHECK-NEXT:    ret void
;
  %qv = load <2 x float>, <2 x float>* %q
  %pv = load <2 x float>, <2 x float>* %p
  store <2 x float> %pv, <2 x float>* %q, align 16
  store <2 x float> %qv, <2 x float>* %p, align 16
  ret void
}

; Same as swap_vectorft1, but the load/stores are in the opposite order.
define void @swap_vectorft2(<2 x float>* nonnull align 16 %p, <2 x float>* nonnull align 16 %q) sanitize_numericalstability {
; CHECK-LABEL: @swap_vectorft2(
; CHECK-NEXT:    [[PV:%.*]] = load <2 x float>, <2 x float>* [[P:%.*]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x float>* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP1]], i64 2)
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[TMP3]], label [[TMP7:%.*]], label [[TMP4:%.*]]
; CHECK:       4:
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP2]] to <2 x double>*
; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x double>, <2 x double>* [[TMP5]], align 1
; CHECK-NEXT:    br label [[TMP9:%.*]]
; CHECK:       7:
; CHECK-NEXT:    [[TMP8:%.*]] = fpext <2 x float> [[PV]] to <2 x double>
; CHECK-NEXT:    br label [[TMP9]]
; CHECK:       9:
; CHECK-NEXT:    [[TMP10:%.*]] = phi <2 x double> [ [[TMP6]], [[TMP4]] ], [ [[TMP8]], [[TMP7]] ]
; CHECK-NEXT:    [[QV:%.*]] = load <2 x float>, <2 x float>* [[Q:%.*]], align 8
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <2 x float>* [[Q]] to i8*
; CHECK-NEXT:    [[TMP12:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_load(i8* [[TMP11]], i64 2)
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i8* [[TMP12]], null
; CHECK-NEXT:    br i1 [[TMP13]], label [[TMP17:%.*]], label [[TMP14:%.*]]
; CHECK:       14:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP12]] to <2 x double>*
; CHECK-NEXT:    [[TMP16:%.*]] = load <2 x double>, <2 x double>* [[TMP15]], align 1
; CHECK-NEXT:    br label [[TMP19:%.*]]
; CHECK:       17:
; CHECK-NEXT:    [[TMP18:%.*]] = fpext <2 x float> [[QV]] to <2 x double>
; CHECK-NEXT:    br label [[TMP19]]
; CHECK:       19:
; CHECK-NEXT:    [[TMP20:%.*]] = phi <2 x double> [ [[TMP16]], [[TMP14]] ], [ [[TMP18]], [[TMP17]] ]
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <2 x float>* [[Q]] to i8*
; CHECK-NEXT:    [[TMP22:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP21]], i64 2)
; CHECK-NEXT:    [[TMP23:%.*]] = extractelement <2 x float> [[PV]], i64 0
; CHECK-NEXT:    [[TMP24:%.*]] = extractelement <2 x double> [[TMP10]], i64 0
; CHECK-NEXT:    [[TMP25:%.*]] = ptrtoint <2 x float>* [[Q]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP23]], double [[TMP24]], i32 4, i64 [[TMP25]])
; CHECK-NEXT:    [[TMP27:%.*]] = extractelement <2 x float> [[PV]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = extractelement <2 x double> [[TMP10]], i64 1
; CHECK-NEXT:    [[TMP29:%.*]] = ptrtoint <2 x float>* [[Q]] to i64
; CHECK-NEXT:    [[TMP30:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP27]], double [[TMP28]], i32 4, i64 [[TMP29]])
; CHECK-NEXT:    [[TMP31:%.*]] = or i32 [[TMP26]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = icmp eq i32 [[TMP31]], 1
; CHECK-NEXT:    [[TMP33:%.*]] = fpext <2 x float> [[PV]] to <2 x double>
; CHECK-NEXT:    [[TMP34:%.*]] = select i1 [[TMP32]], <2 x double> [[TMP33]], <2 x double> [[TMP10]]
; CHECK-NEXT:    [[TMP35:%.*]] = bitcast i8* [[TMP22]] to <2 x double>*
; CHECK-NEXT:    store <2 x double> [[TMP34]], <2 x double>* [[TMP35]], align 1
; CHECK-NEXT:    store <2 x float> [[PV]], <2 x float>* [[Q]], align 16
; CHECK-NEXT:    [[TMP36:%.*]] = bitcast <2 x float>* [[P]] to i8*
; CHECK-NEXT:    [[TMP37:%.*]] = call i8* @__nsan_get_shadow_ptr_for_float_store(i8* [[TMP36]], i64 2)
; CHECK-NEXT:    [[TMP38:%.*]] = extractelement <2 x float> [[QV]], i64 0
; CHECK-NEXT:    [[TMP39:%.*]] = extractelement <2 x double> [[TMP20]], i64 0
; CHECK-NEXT:    [[TMP40:%.*]] = ptrtoint <2 x float>* [[P]] to i64
; CHECK-NEXT:    [[TMP41:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP38]], double [[TMP39]], i32 4, i64 [[TMP40]])
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <2 x float> [[QV]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = extractelement <2 x double> [[TMP20]], i64 1
; CHECK-NEXT:    [[TMP44:%.*]] = ptrtoint <2 x float>* [[P]] to i64
; CHECK-NEXT:    [[TMP45:%.*]] = call i32 @__nsan_internal_check_float_d(float [[TMP42]], double [[TMP43]], i32 4, i64 [[TMP44]])
; CHECK-NEXT:    [[TMP46:%.*]] = or i32 [[TMP41]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = icmp eq i32 [[TMP46]], 1
; CHECK-NEXT:    [[TMP48:%.*]] = fpext <2 x float> [[QV]] to <2 x double>
; CHECK-NEXT:    [[TMP49:%.*]] = select i1 [[TMP47]], <2 x double> [[TMP48]], <2 x double> [[TMP20]]
; CHECK-NEXT:    [[TMP50:%.*]] = bitcast i8* [[TMP37]] to <2 x double>*
; CHECK-NEXT:    store <2 x double> [[TMP49]], <2 x double>* [[TMP50]], align 1
; CHECK-NEXT:    store <2 x float> [[QV]], <2 x float>* [[P]], align 16
; CHECK-NEXT:    ret void
;
  %pv = load <2 x float>, <2 x float>* %p
  %qv = load <2 x float>, <2 x float>* %q
  store <2 x float> %pv, <2 x float>* %q, align 16
  store <2 x float> %qv, <2 x float>* %p, align 16
  ret void
}
